{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import requests\n",
    "import time\n",
    "import shapely\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "from shapely.geometry import asShape\n",
    "from collections import defaultdict\n",
    "from pandas import DataFrame as df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When last we left off...\n",
    "\n",
    "We had produced a neighborhood data json file, and a list of subway stops, that we could combine\n",
    "to make a map -- but \n",
    "\n",
    "Now we want to focus in on elevator outages and how long they're expected to take to resolve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start by reloading our core datasets:\n",
    "with open('neighborhood_to_stations.json') as infile:\n",
    "    neighborhood_to_stations=json.load(infile)\n",
    "with open('stations_to_neighborhoods.json') as infile:\n",
    "    stations_to_neighborhoods=json.load(infile)\n",
    "with open('mta_stations_sorted_by_name.json') as infile:\n",
    "    mta_stations_sorted_by_name=json.load(infile)\n",
    "with open('nyca_stations.json') as infile:\n",
    "    nyca_stations=json.load(infile)\n",
    "with open('all_nyca_station_details.json') as infile:\n",
    "    all_nyca_station_details=json.load(infile)\n",
    "with open('neighborhood_data.json') as infile:\n",
    "    neighborhood_data=json.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, I left myself a bit of a mess. The geotagged station data from the MTA doesn't have any\n",
    "simple id to join it against the accessibility data from NYCA. Let's work on that problem.\n",
    "\n",
    "Let's see if I can correlate name+line across datasets and make it work.\n",
    "\n",
    "... [1 hour later]... Not automatically, but I can do a manual alignment by staring hard at excel.\n",
    "Dump both files ... do a ton of manual analysis ... reimport the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mta_sorted = sorted([\n",
    "    (m['properties']['name'],m['properties']['line'],m['properties']['objectid'])\n",
    "    for m in mta_stations_sorted_by_name\n",
    "])\n",
    "nyca_sorted = sorted([\n",
    "    (n['name'],tuple(n['lines']),n['id'])\n",
    "    for n in nyca_stations\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df(mta_sorted).to_csv('mta_sorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df(nyca_sorted).to_csv('nyca_sorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dr1=df.from_csv('aligned_mta_nyca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('103rd St', '103rd St')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuple of (mta,nyca_id)\n",
    "def format_mta_id(flt):\n",
    "    if not flt or math.isnan(flt):\n",
    "        return None\n",
    "    else:\n",
    "        return str(int(flt))\n",
    "\n",
    "def format_nyca_id(flt):\n",
    "    if not flt or math.isnan(flt):\n",
    "        return None\n",
    "    else:\n",
    "        return int(flt)\n",
    "\n",
    "aligned_objectids = [\n",
    "    (format_mta_id(r[3]),format_nyca_id(r[7]))\n",
    "    for r in dr1.to_records()\n",
    "]\n",
    "mta_stations_to_name={ms['properties']['objectid']:ms['properties']['name'] for ms in mta_stations_sorted_by_name}\n",
    "nyca_stations_to_name={ns['id']:ns['name'] for ns in nyca_stations}\n",
    "first_rec=aligned_objectids[0]\n",
    "(mta_stations_to_name[first_rec[0]],nyca_stations_to_name[first_rec[1]]) # confirming they match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... whew! That was a pain.\n",
    "Now we need to go:\n",
    "* Elevator outage -> NYCA station ID -> MTA station ID -> (point) -> Neighborhood\n",
    "\n",
    "There were some NYCA station IDs that mapped to multiple MTA stations. Let's see if any of those span neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing mta_id for nyca_id 372\n",
      "Missing nyca_id for mta_id 470\n",
      "Missing nyca_id for mta_id 442\n",
      "Missing nyca_id for mta_id 641\n",
      "Missing nyca_id for mta_id 642\n",
      "Missing nyca_id for mta_id 443\n",
      "Missing nyca_id for mta_id 643\n",
      "Missing nyca_id for mta_id 153\n",
      "Missing nyca_id for mta_id 371\n",
      "NYCA id 49 (Atlantic Ave) maps to neighborhoods ['Fort Greene', 'Park Slope-Gowanus']\n",
      "NYCA id 57 (Borough Hall) maps to neighborhoods ['DUMBO-Vinegar Hill-Downtown Brooklyn-Boerum Hill', 'Brooklyn Heights-Cobble Hill']\n",
      "NYCA id 274 (Broadway Junction) maps to neighborhoods ['Bushwick South', 'Ocean Hill']\n",
      "NYCA id 471 (Grand Central - 42nd St) maps to neighborhoods ['Turtle Bay-East Midtown', 'Murray Hill-Kips Bay', 'Midtown-Midtown South']\n",
      "NYCA id 34 (Union Sq - 14th St) maps to neighborhoods ['Hudson Yards-Chelsea-Flatiron-Union Square', 'West Village']\n"
     ]
    }
   ],
   "source": [
    "nyca_station_to_ntacode=defaultdict(lambda:set())\n",
    "#aligned_objectids[0][1]\n",
    "#stations_to_neighborhoods[aligned_objectids[0][0]]\n",
    "for mta_id,nyca_id in aligned_objectids:\n",
    "    if mta_id is None:\n",
    "        print('Missing mta_id for nyca_id {}'.format(nyca_id))\n",
    "    elif nyca_id is None:\n",
    "        print('Missing nyca_id for mta_id {}'.format(mta_id))\n",
    "    elif mta_id in stations_to_neighborhoods:\n",
    "        neighborhoods=stations_to_neighborhoods[mta_id]\n",
    "        if len(neighborhoods) == 1:\n",
    "            nyca_station_to_ntacode[nyca_id].add(neighborhoods[0])\n",
    "        else:\n",
    "            print('Multi-neighborhood data for {}/{}'.format(mta_id,nyca_id))\n",
    "    else:\n",
    "        print('Missing neighborhood data for {}'.format(mta_id))\n",
    "\n",
    "ntacode_to_name={nb['properties']['NTACode']:nb['properties']['NTAName'] for nb in neighborhood_data['features']}\n",
    "for nyca_id,ntacodes in nyca_station_to_ntacode.items():\n",
    "    if len(ntacodes) != 1:\n",
    "        print('NYCA id {} ({}) maps to neighborhoods {}'.format(\n",
    "            nyca_id,\n",
    "            nyca_stations_to_name[nyca_id],\n",
    "            [ntacode_to_name[nb] for nb in ntacodes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MN12'}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyca_station_to_ntacode[106]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... OK. Loaded. Mapped. I'm satisfied that the mappings are good enough. Now let's do what we came here\n",
    "to do and map outages to neighborhoods. \n",
    "\n",
    "## Let's bring it all together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('445', 'about 3 hours', '3 days (04/04 12:00 AM)'),\n",
       " ('291', 'about 9 hours', '1 day (04/03  2:05 AM)'),\n",
       " ('397', 'about 11 hours', '1 day (04/03 12:40 AM)'),\n",
       " ('438', 'about 1 hour', 'about 2 hours (04/01  1:00 PM)'),\n",
       " ('3', '5 days', '7 months (10/31  9:49 AM)'),\n",
       " ('3', '5 days', '7 months (10/31 10:32 AM)'),\n",
       " ('315', '26 minutes', '2 days (04/03 11:54 AM)'),\n",
       " ('25', 'about 8 hours', '1 day (04/03  3:55 AM)'),\n",
       " ('57', '1 day', '1 day (04/03 12:00 AM)'),\n",
       " ('434', 'about 8 hours', '1 day (04/03  3:55 AM)'),\n",
       " ('5', '8 months', 'about 1 month (05/11 10:00 AM)'),\n",
       " ('5', '8 months', 'about 1 month (05/11 12:00 AM)'),\n",
       " ('5', '8 months', 'about 1 month (05/11 12:00 AM)'),\n",
       " ('223', 'about 2 hours', 'about 5 hours (04/01  4:00 PM)'),\n",
       " ('471', 'about 12 hours', '1 day (04/03  2:00 AM)'),\n",
       " ('241', '1 day', 'about 13 hours (04/02 12:00 AM)'),\n",
       " ('46', '1 day', 'about 17 hours (04/02  4:31 AM)')]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyca_elevator_outages=[\n",
    "    (station_nyca_id,m['out_since'],m['return_date_display'])\n",
    "    for station_nyca_id,station_info in all_nyca_station_details.items()\n",
    "    for m in station_info['machines']\n",
    "    if m['out_since'] and m['human_eq_type']=='Elevator'\n",
    "]\n",
    "nyca_elevator_outages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a human scale, it's not clear how to evaluate these outages. A 1-day outage sucks. A 12-month outage sucks a lot\n",
    "more, but not 365 times as much. \n",
    "\n",
    "Originally I was going to discount when an elevator was one of several at a station - but that's not fair; we\n",
    "don't know whether the elevator is the only one *on its platform*.\n",
    "\n",
    "So instead I'm going to badness-score it with simple regexes:\n",
    "* 'day' - 1 point\n",
    "* 'days' - 2 points\n",
    "* 'month' - 5 points\n",
    "* anything else (second, minute, hour) - 0.5 points\n",
    "\n",
    "Max across both (past,expected). \n",
    "Multiple elevator outages at the same station don't count multiple times.\n",
    "\n",
    "However, multiple elevator outages in the **same neighborhood** at different stations do count multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'223': 0.5,\n",
       " '241': 1,\n",
       " '25': 1,\n",
       " '291': 1,\n",
       " '3': 5,\n",
       " '315': 2,\n",
       " '397': 1,\n",
       " '434': 1,\n",
       " '438': 0.5,\n",
       " '445': 2,\n",
       " '46': 1,\n",
       " '471': 1,\n",
       " '5': 5,\n",
       " '57': 1}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_text(text):\n",
    "    if re.search('month',text):\n",
    "        return 5\n",
    "    elif re.search('days',text):\n",
    "        return 2\n",
    "    elif re.search('day',text):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.5\n",
    "\n",
    "def score_outage(outage):\n",
    "    (nyca_id,out_since,return_date)=outage\n",
    "    return max(\n",
    "        score_text(out_since),\n",
    "        score_text(return_date))\n",
    "\n",
    "def flatten_scores(outages):\n",
    "    station_scores=defaultdict(lambda:0)\n",
    "    for outage in outages:\n",
    "        station_scores[outage[0]] = max(\n",
    "            station_scores[outage[0]],\n",
    "            score_outage(outage)\n",
    "        )\n",
    "    return dict(station_scores)\n",
    "\n",
    "station_scores=flatten_scores(nyca_elevator_outages)\n",
    "station_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step! Take the scored station data and turn it into scored neighborhood data.\n",
    "\n",
    "If an elevator outage is in one of my 5 monster stations \n",
    "(Atlantic Av, Boro Hall, Bway Junction, Grand Central, and Union Sq) that span neighborhoods, I'm\n",
    "going to count it as a broken elevator in all 5.\n",
    "\n",
    "TODO: get fancy and divide by total number of stations in that neighborhood - but not right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BK09': 1,\n",
       " 'BK28': 2,\n",
       " 'BK38': 1,\n",
       " 'BK60': 1,\n",
       " 'BX49': 1,\n",
       " 'BX63': 1,\n",
       " 'MN13': 2,\n",
       " 'MN17': 1.5,\n",
       " 'MN19': 6,\n",
       " 'MN20': 1,\n",
       " 'MN23': 1,\n",
       " 'MN24': 1,\n",
       " 'MN27': 5,\n",
       " 'MN35': 1,\n",
       " 'QN17': 0.5}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def station_scores_to_neighborhood_data(station_scores):\n",
    "    neighborhood_scores=defaultdict(lambda:0)\n",
    "    for station_id,station_score in station_scores.items():\n",
    "        for neighborhood in nyca_station_to_ntacode[int(station_id)]:\n",
    "            neighborhood_scores[neighborhood] = neighborhood_scores[neighborhood]+station_score    \n",
    "    return dict(neighborhood_scores)\n",
    "\n",
    "neighborhood_scores=station_scores_to_neighborhood_data(station_scores)\n",
    "neighborhood_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And, once again, enrich the original neighborhood_data geojson with neighborhood_score:\n",
    "for n in neighborhood_data['features']:\n",
    "    n_id=n['properties']['NTACode']\n",
    "    n['properties']['elevator_outage_score'] = neighborhood_scores.get(n_id,0)\n",
    "\n",
    "#... and write it back out:\n",
    "with open('neighborhood_data_current_outages.json','w') as outfile:\n",
    "    json.dump(neighborhood_data,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
